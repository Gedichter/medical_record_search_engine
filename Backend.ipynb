{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backend\n",
    "\n",
    "This notebook loads the original/indexed data and w2vec models. It then launches a server backend which enables querying by first connecting via TCP, and then sending a series of commands, which the server responds to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run includes/imports.py\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "from includes.stringop import StringOp\n",
    "from includes.w2vec import W2VecModel\n",
    "from includes.query_expander import QueryExpander"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W2VEC = W2VecModel()\n",
    "CHARGRAM = W2VecModel()\n",
    "CHARGRAM.load_model('index/model_char.w2v')\n",
    "W2VEC.load_model('index/model_word.w2v')\n",
    "Expander = QueryExpander(W2VEC, CHARGRAM) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/NOTEEVENTS.csv', dtype={'TEXT': str}, usecols = ['TEXT'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Server definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Server():\n",
    "    wlist = []\n",
    "    neglist = []\n",
    "    dicts = []\n",
    "    verbosity = False\n",
    "    \n",
    "    def __init__(self, verbosity):\n",
    "        '''\n",
    "        Initializes the server.\n",
    "        verbosity: determines if the server should perform extensive printing of intermediate results for debugging purposes.\n",
    "        '''\n",
    "        self.verbosity = verbosity\n",
    "        with open('words/negative.txt') as f: #load list of negative words\n",
    "            self.neglist = f.readlines()\n",
    "        self.neglist = [str.lower(x.strip()) for x in self.neglist]\n",
    "        with open('words/conditions.txt') as f: #load list of supported conditions\n",
    "            wlist = f.readlines()\n",
    "            wlist = [str.lower(x.strip()) for x in wlist]\n",
    "\n",
    "        wordlist = []\n",
    "        for w in wlist:\n",
    "            wordlist.append(w.split('/'))\n",
    "        self.wlist = wordlist\n",
    "    \n",
    "    #-----------------------\n",
    "    #QUERY PROCESSING PART\n",
    "    #-----------------------\n",
    "    \n",
    "    def read_index(self, filepath):\n",
    "        '''\n",
    "        Reads a single index file. Use when single-threaded indexing was performed previously.\n",
    "        filepath: path to the index.json file.\n",
    "        '''\n",
    "        self.dicts = []\n",
    "        with open(filepath) as f:\n",
    "            for line in f:\n",
    "                self.dicts.append(json.loads(line))\n",
    "                \n",
    "    def read_indices(self, dirpath):\n",
    "        '''\n",
    "        Reads multiple index files. Use when multi-threaded indexing was performed previously.\n",
    "        dirpath: path to index directory, containing index{i}.json files.\n",
    "        '''\n",
    "        self.dicts = []\n",
    "        files = list(sorted(glob.glob(os.path.join(dirpath, 'pindex*.json')))) \n",
    "        for file in files: \n",
    "            print('reading', file)\n",
    "            f = open(file)\n",
    "            for line in f:\n",
    "                self.dicts.append(json.loads(line))\n",
    "            f.close()\n",
    "                \n",
    "    def get_condition_attributes(self, query):\n",
    "        '''\n",
    "        Extracts condition and attributes from a given full-text query.\n",
    "        query: the query to extract condition and attributes from.\n",
    "        '''\n",
    "        attributes = []\n",
    "        allwords = query.split(' ')\n",
    "        condition = ''\n",
    "        resdict = StringOp.find_condition(self.wlist, query)\n",
    "        for k,v in resdict.items():\n",
    "            condition = k\n",
    "            record = not (0 in v)\n",
    "            word = ''\n",
    "            for i in range(len(query)):\n",
    "                if record and query[i]!=' ':\n",
    "                    word+=query[i]\n",
    "                if query[i]==' ':\n",
    "                    if len(word)>0:\n",
    "                        attributes.append(word)\n",
    "                        word = ''\n",
    "                    if (i+1) in v:\n",
    "                        record=False\n",
    "                    else:\n",
    "                        record=True\n",
    "            if len(word)>0: attributes.append(word)\n",
    "        return condition, attributes\n",
    "               \n",
    "    def query(self, query, polarity=True, dosort=True, expand=True, verbose=False, damping=1):\n",
    "        '''\n",
    "        Executes a given query and returns results.\n",
    "        query: the query to execute.\n",
    "        polarity: the polarity of the query, either True if condition should be present, or False if not.\n",
    "        expand: determines if the query should be expanded by using synonyms. if expanded, multiple queries will be run internally, and the aggregated result will be returned.\n",
    "        verbose: determines level of verbosity.\n",
    "        damping: determines the weight deduction applied to the extended queries. if <1, extended queries will experience extra downweighting. only applied if expand is set to True.\n",
    "        '''\n",
    "        if not expand: #simply call single query function\n",
    "            return self.single_query(query, polarity, dosort, verbose=verbose)\n",
    "        else: #expand attributes\n",
    "            condition, attributes = self.get_condition_attributes(query)\n",
    "            words_interest_condition = set(self.get_condition_synonyms(condition))\n",
    "            words_interest_attributes = set(attributes)\n",
    "            alternatives = []\n",
    "            simscore = {}\n",
    "            for att in attributes: #expand each attribute using the QueryExpander\n",
    "                expansion = Expander.expand_word(att, syn_threshold=0.2, var_thres_sim=20, var_thres_dis=-1) \n",
    "                alternatives.append(expansion)\n",
    "                for k,v in expansion.items():\n",
    "                    if not k in simscore: simscore[k] = v\n",
    "                    words_interest_attributes.update([k])\n",
    "            combine = itertools.product(*alternatives) #creates all possible combinations of synonym queries\n",
    "            if verbose:\n",
    "                print('words of interest condition', words_interest_condition)\n",
    "                print('words of interest attributes', words_interest_attributes)\n",
    "            \n",
    "            overall_result = np.full(len(self.dicts), float('-inf'))\n",
    "            for c in combine:\n",
    "                newquery = condition + ' ' + \" \".join(c)\n",
    "                query_weight = 1 #compute query weight based on the similarity score given by the QueryExpander\n",
    "                for element in c:\n",
    "                    query_weight*=simscore[element]\n",
    "                query_weight = query_weight*damping #apply damping factor for the non-original queries\n",
    "                if verbose:\n",
    "                    print('alternative query:', newquery, ', weight:', query_weight)\n",
    "                #run individual query\n",
    "                qresult, wic, wia = self.single_query(newquery, polarity, dosort=False, verbose=verbose)\n",
    "                vals = np.array(list(qresult.values()))*query_weight\n",
    "                overall_result = np.maximum(overall_result, vals) #merging results by taking the max of all, element-wise\n",
    "            ct=0\n",
    "            for k,v in qresult.items(): #recycle last dict here\n",
    "                qresult[k] = overall_result[ct]\n",
    "                ct+=1\n",
    "            if dosort:\n",
    "                qresult = sorted(qresult.items(), key=operator.itemgetter(1),reverse=True)\n",
    "            return qresult, words_interest_condition, words_interest_attributes\n",
    "        \n",
    "    def single_query(self, query, polarity=True, dosort=True, verbose=False):\n",
    "        '''\n",
    "        Executes a single query without performing any expansion, and returns the result.\n",
    "        query: the query to execute.\n",
    "        polarity: the polarity of the query, either True if condition should be present, or False if not.\n",
    "        dosort: determines if search results should be sorted by the relevancy assigned, or left in their original order.\n",
    "        verbose: determines level of verbosity.\n",
    "        '''\n",
    "        condition, attributes = self.get_condition_attributes(query)\n",
    "        words_interest_condition = set(self.get_condition_synonyms(condition))\n",
    "        words_interest_attributes = set(attributes)\n",
    "        verbose=True\n",
    "        if verbose:\n",
    "            print('running query [' + ('positive' if polarity else 'negative') + ']')\n",
    "            print('condition', condition)\n",
    "            print('attributes', attributes)\n",
    "            print('words of interest condition', words_interest_condition)\n",
    "            print('words of interest attributes', words_interest_attributes)            \n",
    "         \n",
    "        results = {}\n",
    "        index = 0\n",
    "        for d in self.dicts:\n",
    "            #cover trivial cases:\n",
    "            if polarity and not condition in d:\n",
    "                results[index] = -1 #irrelevant, condition not present at all\n",
    "            elif polarity and condition in d and len(set(d[condition]) & set(self.neglist))>0: #looking for positive, classified as negative\n",
    "                results[index] = -0.5\n",
    "            elif not polarity and not condition in d: #condition not mentioned. it could be a negative, we can't tell.\n",
    "                results[index] = 0\n",
    "            elif not polarity and condition in d and not len(set(d[condition]) & set(self.neglist))>0: #looking for negative, but we classified as positive\n",
    "                results[index] = -0.5\n",
    "                \n",
    "            #in all other cases, perform precise matching by comparing attributes\n",
    "            elif condition in d: \n",
    "                matches_condition = d[condition]['-total-'] \n",
    "                matches_attributes = 0\n",
    "                perc_matched = 1\n",
    "                for a in attributes:\n",
    "                    if a in d[condition]:\n",
    "                        matches_attributes+=d[condition][a] \n",
    "                        perc_matched+=1\n",
    "                perc_matched/=(len(attributes)+1)        \n",
    "                results[index] = perc_matched        \n",
    "            \n",
    "            index+=1\n",
    "        if dosort: results = sorted(results.items(), key=operator.itemgetter(1),reverse=True)\n",
    "        return results, words_interest_condition, words_interest_attributes\n",
    "    \n",
    "    def query_complex(self, query, expand, verbose=False):\n",
    "        '''\n",
    "        Executes a complex query, i.e. a joint query with multiple criteria, and returns the result.\n",
    "        query: the query to execute.\n",
    "        expand: determines if the query should be expanded by using synonyms. if expanded, multiple queries will be run internally, and the aggregated result will be returned.\n",
    "        verbose: determines level of verbosity.\n",
    "        '''\n",
    "    \n",
    "        if query.startswith('('): query=\"+\" + query\n",
    "        words_interest_condition = set()\n",
    "        words_interest_attributes = set()\n",
    "        \n",
    "        #parse complex query in lists of positive and negative queries\n",
    "        indices = [m.start() for m in re.finditer('\\(', query)]\n",
    "        posqueries = []\n",
    "        negqueries = []\n",
    "        for ind in indices:\n",
    "            polarity = query[ind-1]\n",
    "            if polarity=='+':\n",
    "                posqueries.append(query[ind+1:].split(')')[0])\n",
    "            elif polarity=='-':\n",
    "                negqueries.append(query[ind+1:].split(')')[0])\n",
    "        \n",
    "        if verbose:\n",
    "            print('positive queries:', posqueries)\n",
    "            print('negative queries:', negqueries)\n",
    "\n",
    "        im_result = None\n",
    "        overall_res = np.ones(len(self.dicts))\n",
    "        \n",
    "        for j in range(2):\n",
    "            q_run = posqueries if j==0 else negqueries\n",
    "            polar = True if j==0 else False\n",
    "            \n",
    "        \n",
    "            for i in range(len(q_run)): #run all individual queries, also expanding all of them if requested\n",
    "                condition, attributes = self.get_condition_attributes(q_run[i])\n",
    "                words_interest_condition.update(self.get_condition_synonyms(condition))\n",
    "\n",
    "                im_result, wic, wia = self.query(q_run[i], polarity=polar, dosort=False, expand=expand, verbose=verbose)\n",
    "                words_interest_condition.update(wic)\n",
    "                words_interest_attributes.update(wia)\n",
    "                vals = np.array(list(im_result.values()))\n",
    "                overall_res = overall_res+vals\n",
    "        \n",
    "        ct=0\n",
    "        for k,v in im_result.items(): #just recycle last dict\n",
    "            im_result[k] = overall_res[ct]\n",
    "            ct+=1\n",
    "        im_result = sorted(im_result.items(), key=operator.itemgetter(1), reverse=True)\n",
    "        return im_result, words_interest_condition, words_interest_attributes\n",
    "    \n",
    "    def get_condition_synonyms(self, condition):\n",
    "        '''\n",
    "        Returns all synonyms known for a given condition.\n",
    "        condition: the condition to find synonyms of.\n",
    "        '''\n",
    "        for lst in self.wlist:\n",
    "            if condition in lst:\n",
    "                return lst\n",
    "        return None #if no condition identified.\n",
    "    \n",
    "    def find_summary(self, fulltext, query, wia, wic):\n",
    "        '''\n",
    "        Tries to find a summary sentence (i.e. most relevant part) of a full-text document, given the user query.\n",
    "        fulltext: the whole medical report.\n",
    "        query: the user query that was executed.\n",
    "        wia: all words of interest for the condition.\n",
    "        wic: all words of interest for the attributes.\n",
    "        '''\n",
    "        all_indices = set()\n",
    "        for w in wic:\n",
    "            indices = [m.start() for m in re.finditer(w.lower(), fulltext.lower())]\n",
    "            all_indices.update(indices)\n",
    "        #within all neighborhoods around those indices, find the ones that maximize the number of attributes around them\n",
    "        nsize = 90\n",
    "        highest_total = -1\n",
    "        highest_ind = 0\n",
    "        for ind in all_indices:\n",
    "            subtext = fulltext[max(0,ind-nsize):min(len(fulltext), ind+nsize)]\n",
    "            totalmatches = 0\n",
    "            for w in wia:\n",
    "                matches = len([m.start() for m in re.finditer(w, subtext)])\n",
    "                if matches>0: totalmatches+=1\n",
    "            if totalmatches>highest_total:\n",
    "                highest_total = totalmatches\n",
    "                highest_ind = ind\n",
    "        return '...' + fulltext[int(max(0,highest_ind-nsize)):int(min(len(fulltext), highest_ind+nsize))].replace('@','').replace('|','').replace('\\n', ' ').replace('-', '').replace('?', '') + '...'\n",
    "    \n",
    "    #-----------------------\n",
    "    #NETWORK PART\n",
    "    #-----------------------\n",
    "    \n",
    "    def send(self, s, conn):\n",
    "        '''\n",
    "        Sends the given string to a connected TCP-client.\n",
    "        s: the string to send.\n",
    "        conn: the connection to send to.\n",
    "        '''\n",
    "        buffer = str.encode(s)\n",
    "        conn.send(str.encode(str(len(buffer))))\n",
    "        conn.send(buffer)\n",
    "        \n",
    "    def handle_request(self, req, conn):\n",
    "        '''\n",
    "        Handles a specific request made by a client.\n",
    "        req: the request received as a string.\n",
    "        conn: the connection it was sent from.\n",
    "        '''\n",
    "        req = str(req, 'utf-8')\n",
    "        print('handling ' + str(req) + '...')\n",
    "        command = req.split(':')[0]\n",
    "        args = req.split(':')[1]\n",
    "        if command=='serve': #serve a specific report based on its index\n",
    "            print('sending report ', args)\n",
    "            self.send(data.iloc[int(args)]['TEXT'], conn)\n",
    "        elif command.startswith('query'): #execute a query.\n",
    "            args = args.replace(',', ' ')\n",
    "            expa = 'expand' in command\n",
    "            cplx = 'complex' in command\n",
    "            print('executing query', args, \"expand:\", expa, \"complex:\", cplx)\n",
    "            \n",
    "            try:\n",
    "                ranking, wic, wia = self.query(args, expand=expa, verbose=self.verbosity) if not cplx else self.query_complex(args, expand=expa, verbose=self.verbosity)\n",
    "                \n",
    "                if len(ranking)==0:\n",
    "                    self.send('err_no_match', conn)\n",
    "                else:\n",
    "                    print('query completed, returning results...')\n",
    "                    self.send('|'.join(wic.union(wia)) + '|', conn) #send words that are to highlight by the client\n",
    "                    s = ''\n",
    "                    for item in ranking[0:50]: #formulate result of top 50 results\n",
    "                        s+=str(item[0]) + '@' + str(item[1]) + '@' + self.find_summary(data.iloc[item[0]]['TEXT'], args, wia, wic) + '|'\n",
    "                    self.send(s[0:len(s)-1], conn) #send back results\n",
    "            except:\n",
    "                self.send('err_invalid', conn)\n",
    "        else: #unknown command\n",
    "            self.send('err_invalid', conn)\n",
    "\n",
    "    def run(self, TCP_IP, TCP_PORT, BUFFER_SIZE=1024):\n",
    "        '''\n",
    "        Runs the server in blocking mode.\n",
    "        TCP_IP: the IP to listen from.\n",
    "        TCP_PORT: the TCP port to listen from.\n",
    "        BUFFER_SIZE: the buffer size used.\n",
    "        '''\n",
    "        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "        s.bind((TCP_IP, TCP_PORT))\n",
    "        s.listen(1)\n",
    "        \n",
    "        while(True):\n",
    "            print('waiting for incoming connections...')\n",
    "            conn, addr = s.accept()\n",
    "            print('Connection address:', addr)\n",
    "            try:\n",
    "                while(True):\n",
    "                    req = conn.recv(BUFFER_SIZE)\n",
    "                    if not req: break\n",
    "                    if len(req)<=1: continue #ignore tests if alive\n",
    "                    self.handle_request(req, conn)\n",
    "\n",
    "            except:\n",
    "                print('connection closed.')\n",
    "                conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executing the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sv = Server(False)\n",
    "sv.read_indices('index/')\n",
    "sv.run('127.0.0.1', 5008)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check: simple query\n",
    "\n",
    "These can be executed from here without having to connect a client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#simple query:\n",
    "sv.query('hemorrhage acute', polarity=True, dosort=True, expand=True, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check: complex query\n",
    "\n",
    "Complex queries follow this form: \\textit{(query 1)+(query 2)-(query 3)+(query 4)...}\n",
    "Here, each query contains exactly one condition and an arbitrary number of attributes related to it. The \"+\" indicates that the given condition with its attributes has to be present, the \"-\" that is has to be absent. Always wrap queries in parenthesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#complex query:\n",
    "sv.query_complex('(hemorrhage acute brain)-(hypertension)', expand=False, verbose=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
